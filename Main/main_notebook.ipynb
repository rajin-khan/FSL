{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'labelImg'...\n",
      "remote: Enumerating objects: 2097, done.\u001b[K\n",
      "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
      "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
      "remote: Total 2097 (delta 0), reused 0 (delta 0), pack-reused 2093 (from 2)\u001b[K\n",
      "Receiving objects: 100% (2097/2097), 237.14 MiB | 4.56 MiB/s, done.\n",
      "Resolving deltas: 100% (1245/1245), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/HumanSignal/labelImg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation done for separate sachets.\n",
    "### (Used albumenation library)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation for HORLICKS AHFD STD CTSL 18ML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/albumentations/core/validation.py:87: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 5 augmented images for horlicks2\n",
      "Saved 5 augmented images for horlicks3\n",
      "Saved 5 augmented images for horlicks1\n",
      "Saved 5 augmented images for horlicks4\n",
      "Saved 5 augmented images for horlicks5\n",
      "Saved 5 augmented images for horlicks6\n",
      "Augmentation complete for all images.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Define input and output directories\n",
    "input_folder = \"/Users/rajin/Desktop/trainimages/horlicks\"  # Folder with original images\n",
    "output_folder = \"augmented_horlicks\"  # Folder to save augmented images\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Define augmentations\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),  # 50% chance of flipping\n",
    "    A.RandomBrightnessContrast(p=0.2),  # Random brightness/contrast adjustment\n",
    "    A.GaussianBlur(p=0.1),  # Apply slight blur\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),  # Random transformations\n",
    "    A.CLAHE(p=0.2)  # Apply Contrast Limited Adaptive Histogram Equalization\n",
    "])\n",
    "\n",
    "num_variations = 5  # Number of augmented images per original image\n",
    "\n",
    "# Process all images in the folder\n",
    "image_paths = glob.glob(os.path.join(input_folder, \"*.jpg\"))  # Modify for other formats\n",
    "\n",
    "for img_path in image_paths:\n",
    "    # Read image\n",
    "    image = cv2.imread(img_path)\n",
    "    if image is None:\n",
    "        print(f\"Error loading {img_path}\")\n",
    "        continue\n",
    "\n",
    "    filename = os.path.basename(img_path).split('.')[0]  # Get filename without extension\n",
    "\n",
    "    for i in range(num_variations):  # Generate multiple variations\n",
    "        augmented = transform(image=image)[\"image\"]\n",
    "\n",
    "        # Save augmented image with index\n",
    "        save_path = os.path.join(output_folder, f\"{filename}_aug_{i}.jpg\")\n",
    "        cv2.imwrite(save_path, augmented)\n",
    "\n",
    "    print(f\"Saved {num_variations} augmented images for {filename}\")\n",
    "\n",
    "print(\"Augmentation complete for all images.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation for CLEAR MEN SHAMP CSM 5ML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 5 augmented images for clear1\n",
      "Saved 5 augmented images for clear3\n",
      "Saved 5 augmented images for clear14\n",
      "Saved 5 augmented images for clear15\n",
      "Saved 5 augmented images for clear2\n",
      "Saved 5 augmented images for clear6\n",
      "Saved 5 augmented images for clear11\n",
      "Saved 5 augmented images for clear10\n",
      "Saved 5 augmented images for clear7\n",
      "Saved 5 augmented images for clear5\n",
      "Saved 5 augmented images for clear12\n",
      "Saved 5 augmented images for clear13\n",
      "Saved 5 augmented images for clear4\n",
      "Saved 5 augmented images for clear9\n",
      "Saved 5 augmented images for clear8\n",
      "Augmentation complete for all images.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Define input and output directories\n",
    "input_folder = \"/Users/rajin/Desktop/trainimages/clear\"  # Folder with original images\n",
    "output_folder = \"augmented_clear\"  # Folder to save augmented images\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Define augmentations\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),  # 50% chance of flipping\n",
    "    A.RandomBrightnessContrast(p=0.2),  # Random brightness/contrast adjustment\n",
    "    A.GaussianBlur(p=0.1),  # Apply slight blur\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),  # Random transformations\n",
    "    A.CLAHE(p=0.2)  # Apply Contrast Limited Adaptive Histogram Equalization\n",
    "])\n",
    "\n",
    "num_variations = 5  # Number of augmented images per original image\n",
    "\n",
    "# Process all images in the folder\n",
    "image_paths = glob.glob(os.path.join(input_folder, \"*.jpg\"))  # Modify for other formats\n",
    "\n",
    "for img_path in image_paths:\n",
    "    # Read image\n",
    "    image = cv2.imread(img_path)\n",
    "    if image is None:\n",
    "        print(f\"Error loading {img_path}\")\n",
    "        continue\n",
    "\n",
    "    filename = os.path.basename(img_path).split('.')[0]  # Get filename without extension\n",
    "\n",
    "    for i in range(num_variations):  # Generate multiple variations\n",
    "        augmented = transform(image=image)[\"image\"]\n",
    "\n",
    "        # Save augmented image with index\n",
    "        save_path = os.path.join(output_folder, f\"{filename}_aug_{i}.jpg\")\n",
    "        cv2.imwrite(save_path, augmented)\n",
    "\n",
    "    print(f\"Saved {num_variations} augmented images for {filename}\")\n",
    "\n",
    "print(\"Augmentation complete for all images.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation for DOVE CNDTIONR IRP DOLCE 7ML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 5 augmented images for doveconditioner8\n",
      "Saved 5 augmented images for doveconditioner9\n",
      "Saved 5 augmented images for doveconditioner12\n",
      "Saved 5 augmented images for doveconditioner11\n",
      "Saved 5 augmented images for doveconditioner10\n",
      "Saved 5 augmented images for doveconditioner2\n",
      "Saved 5 augmented images for doveconditioner3\n",
      "Saved 5 augmented images for doveconditioner1\n",
      "Saved 5 augmented images for doveconditioner4\n",
      "Saved 5 augmented images for doveconditioner5\n",
      "Saved 5 augmented images for doveconditioner7\n",
      "Saved 5 augmented images for doveconditioner6\n",
      "Augmentation complete for all images.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Define input and output directories\n",
    "input_folder = \"/Users/rajin/Desktop/trainimages/doveconditioner\"  # Folder with original images\n",
    "output_folder = \"augmented_doveconditioner\"  # Folder to save augmented images\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Define augmentations\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),  # 50% chance of flipping\n",
    "    A.RandomBrightnessContrast(p=0.2),  # Random brightness/contrast adjustment\n",
    "    A.GaussianBlur(p=0.1),  # Apply slight blur\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),  # Random transformations\n",
    "    A.CLAHE(p=0.2)  # Apply Contrast Limited Adaptive Histogram Equalization\n",
    "])\n",
    "\n",
    "num_variations = 5  # Number of augmented images per original image\n",
    "\n",
    "# Process all images in the folder\n",
    "image_paths = glob.glob(os.path.join(input_folder, \"*.jpg\"))  # Modify for other formats\n",
    "\n",
    "for img_path in image_paths:\n",
    "    # Read image\n",
    "    image = cv2.imread(img_path)\n",
    "    if image is None:\n",
    "        print(f\"Error loading {img_path}\")\n",
    "        continue\n",
    "\n",
    "    filename = os.path.basename(img_path).split('.')[0]  # Get filename without extension\n",
    "\n",
    "    for i in range(num_variations):  # Generate multiple variations\n",
    "        augmented = transform(image=image)[\"image\"]\n",
    "\n",
    "        # Save augmented image with index\n",
    "        save_path = os.path.join(output_folder, f\"{filename}_aug_{i}.jpg\")\n",
    "        cv2.imwrite(save_path, augmented)\n",
    "\n",
    "    print(f\"Saved {num_variations} augmented images for {filename}\")\n",
    "\n",
    "print(\"Augmentation complete for all images.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Annotation completed with LabelImg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (8.3.86)\n",
      "Requirement already satisfied: opencv-python in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (4.67.1)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from ultralytics) (2.1.1)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from ultralytics) (3.10.1)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from ultralytics) (11.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from ultralytics) (1.15.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from ultralytics) (2.6.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from ultralytics) (0.21.0)\n",
      "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=1.8.0->ultralytics) (75.9.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ultralytics opencv-python tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split into train/val/test.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Paths\n",
    "base_dir = \"/Users/rajin/Developer/ITNSHIP/RETAIL-ANALYSIS/Main/data\"\n",
    "image_dir = os.path.join(base_dir, \"images\")\n",
    "label_dir = os.path.join(base_dir, \"labels\")\n",
    "\n",
    "output_dir = \"dataset\"\n",
    "train_dir = os.path.join(output_dir, \"train\")\n",
    "val_dir = os.path.join(output_dir, \"val\")\n",
    "test_dir = os.path.join(output_dir, \"test\")\n",
    "\n",
    "# Create directories\n",
    "for split in [train_dir, val_dir, test_dir]:\n",
    "    os.makedirs(os.path.join(split, \"images\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(split, \"labels\"), exist_ok=True)\n",
    "\n",
    "# Get all image names\n",
    "images = [f for f in os.listdir(image_dir) if f.endswith(\".jpg\")]\n",
    "\n",
    "# Shuffle and split\n",
    "random.shuffle(images)\n",
    "train_split = int(0.7 * len(images))\n",
    "val_split = int(0.2 * len(images))\n",
    "\n",
    "train_images = images[:train_split]\n",
    "val_images = images[train_split:train_split + val_split]\n",
    "test_images = images[train_split + val_split:]\n",
    "\n",
    "# Function to copy images and labels\n",
    "def move_files(images, dest):\n",
    "    for img in images:\n",
    "        shutil.copy(os.path.join(image_dir, img), os.path.join(dest, \"images\", img))\n",
    "        label_path = os.path.join(label_dir, img.replace(\".jpg\", \".txt\"))\n",
    "        if os.path.exists(label_path):\n",
    "            shutil.copy(label_path, os.path.join(dest, \"labels\", img.replace(\".jpg\", \".txt\")))\n",
    "\n",
    "move_files(train_images, train_dir)\n",
    "move_files(val_images, val_dir)\n",
    "move_files(test_images, test_dir)\n",
    "\n",
    "print(\"Dataset split into train/val/test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset.yaml set up."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
